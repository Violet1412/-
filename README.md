# 对抗样本生成工具
## 1 Cleverhans
[cleverhans](https://github.com/tensorflow/cleverhans)

## 2 Foolbox
[foolbox](https://github.com/bethgelab/foolbox)

## 3 ART(adversarial-robustness-toolbox)
[ART](https://github.com/IBM/adversarial-robustness-toolbox)
Adversarial Robustness Toolbox（ART）是一个用于机器学习安全的Python库。ART提供工具，使开发人员和研究人员能够保护和评估机器学习模型和应用程序免受规避、中毒、提取和推理的对抗性威胁。
支持多个流行的机器学习框架（TensorFlow、Keras、PyTorch、MXNet、scikit-learn、XGBoost、LightGBM、CatBoost、GPy）
支持多种数据类型（图像、表格、音频、视频等）和机器学习任务（分类、对象检测、语音识别、生成、认证等）。


## 4 Advertorch
[advertorch](https://github.com/BorealisAI/advertorch)

## 5 Deeprust
[deeprust](https://github.com/DSE-MSU/DeepRobust)

## 6 adversarial-attacks-pytorch
[adversarial-attacks-pytorch](https://github.com/Harry24k/adversarial-attacks-pytorch)

## 

# 其他类型工具
## 1 EvalDNN
[EvalDNN](https://github.com/yqtianust/EvalDNN)

## 2 responsible-ai-toolbox
[responsible-ai-toolbox](https://github.com/mit-ll-responsible-ai/responsible-ai-toolbox)
以PyTorch为中心的工具，用于评估和增强人工智能模型的鲁棒性和可解释性。

## 3 robustbench
[robustbench](https://github.com/RobustBench/robustbench)

## 4 MAIR
[MAIR](https://github.com/Harry24k/MAIR)
